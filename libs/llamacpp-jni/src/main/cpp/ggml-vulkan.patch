diff --git a/ggml/src/ggml-vulkan/ggml-vulkan.cpp b/ggml/src/ggml-vulkan/ggml-vulkan.cpp
index 178d8eb3d..2452abe71 100644
--- a/ggml/src/ggml-vulkan/ggml-vulkan.cpp
+++ b/ggml/src/ggml-vulkan/ggml-vulkan.cpp
@@ -3610,6 +3610,7 @@ static vk_device ggml_vk_get_device(size_t idx) {
         bool amd_shader_core_properties2 = false;
         bool pipeline_robustness = false;
         bool coopmat2_support = false;
+        bool shader_non_semantic_info = false;
         device->coopmat_support = false;
         device->integer_dot_product = false;
         bool bfloat16_support = false;
@@ -3629,6 +3630,8 @@ static vk_device ggml_vk_get_device(size_t idx) {
                 pipeline_robustness = true;
             } else if (strcmp("VK_EXT_subgroup_size_control", properties.extensionName) == 0) {
                 device->subgroup_size_control = true;
+            } else if (strcmp("VK_KHR_shader_non_semantic_info", properties.extensionName) == 0) {
+                shader_non_semantic_info = true;
 #if defined(GGML_VULKAN_COOPMAT_GLSLC_SUPPORT)
             } else if (strcmp("VK_KHR_cooperative_matrix", properties.extensionName) == 0 &&
                        !getenv("GGML_VK_DISABLE_COOPMAT")) {
@@ -3993,18 +3996,21 @@ static vk_device ggml_vk_get_device(size_t idx) {
 #endif
         }
 
+        // 16-bit storage: if not supported, fall back to disabling fp16 features; only request extension when available
         if (!vk11_features.storageBuffer16BitAccess) {
-            std::cerr << "ggml_vulkan: device " << GGML_VK_NAME << idx << " does not support 16-bit storage." << std::endl;
-            throw std::runtime_error("Unsupported device");
+            std::cerr << "ggml_vulkan: device " << GGML_VK_NAME << idx << " does not support 16-bit storage, falling back to 32-bit mode." << std::endl;
+            device->fp16 = false;
+        } else if (fp16_storage) {
+            device_extensions.push_back("VK_KHR_16bit_storage");
         }
 
-        device_extensions.push_back("VK_KHR_16bit_storage");
-
 #ifdef GGML_VULKAN_VALIDATE
-        device_extensions.push_back("VK_KHR_shader_non_semantic_info");
+        if (shader_non_semantic_info) {
+            device_extensions.push_back("VK_KHR_shader_non_semantic_info");
+        }
 #endif
 
-        if (device->fp16) {
+        if (device->fp16 && fp16_compute) {
             device_extensions.push_back("VK_KHR_shader_float16_int8");
         }
 
@@ -4395,11 +4401,19 @@ static void ggml_vk_instance_init() {
     }
     VK_LOG_DEBUG("ggml_vk_instance_init()");
 
+#if defined(VULKAN_HPP_DISPATCH_LOADER_DYNAMIC)
+    // Initialize global Vulkan-HPP dispatcher before any HPP global calls
+    VULKAN_HPP_DEFAULT_DISPATCHER.init(vkGetInstanceProcAddr);
+#endif
+
     uint32_t api_version = vk::enumerateInstanceVersion();
 
     if (api_version < VK_API_VERSION_1_2) {
-        std::cerr << "ggml_vulkan: Error: Vulkan 1.2 required." << std::endl;
-        GGML_ABORT("fatal error");
+        // Lower than 1.2: skip Vulkan backend gracefully
+        std::cerr << "ggml_vulkan: Info: Vulkan 1.2 required; skipping Vulkan backend (api="
+                  << VK_VERSION_MAJOR(api_version) << "." << VK_VERSION_MINOR(api_version) << ")" << std::endl;
+        vk_instance_initialized = true;
+        return;
     }
 
     vk::ApplicationInfo app_info{ "ggml-vulkan", 1, nullptr, 0, api_version };
@@ -4448,6 +4462,10 @@ static void ggml_vk_instance_init() {
         GGML_LOG_DEBUG("ggml_vulkan: Validation layers enabled\n");
     }
     vk_instance.instance = vk::createInstance(instance_create_info);
+#if defined(VULKAN_HPP_DISPATCH_LOADER_DYNAMIC)
+    // Initialize instance-level dispatcher
+    VULKAN_HPP_DEFAULT_DISPATCHER.init(vk_instance.instance);
+#endif
     vk_instance_initialized = true;
 
     if (debug_utils_ext) {
@@ -4568,7 +4586,7 @@ static void ggml_vk_instance_init() {
         }
 
         // If no dedicated GPUs found, fall back to the first non-CPU device.
-        // If only CPU devices are available, return without devices.
+        // If only CPU devices are available, use the first CPU device as last resort.
         if (vk_instance.device_indices.empty()) {
             for (size_t i = 0; i < devices.size(); i++) {
                 if (devices[i].getProperties().deviceType != vk::PhysicalDeviceType::eCpu) {
@@ -4578,6 +4596,16 @@ static void ggml_vk_instance_init() {
             }
         }
 
+        // Last resort: pick a CPU device (e.g., SwiftShader) if present
+        if (vk_instance.device_indices.empty()) {
+            for (size_t i = 0; i < devices.size(); i++) {
+                if (devices[i].getProperties().deviceType == vk::PhysicalDeviceType::eCpu) {
+                    vk_instance.device_indices.push_back(i);
+                    break;
+                }
+            }
+        }
+
         if (vk_instance.device_indices.empty()) {
             GGML_LOG_INFO("ggml_vulkan: No devices found.\n");
             return;
@@ -11417,6 +11445,12 @@ static ggml_backend_buffer_t ggml_backend_vk_host_buffer_type_alloc_buffer(ggml_
         return ggml_backend_buft_alloc_buffer(ggml_backend_cpu_buffer_type(), size);
     }
 
+    if (ptr == nullptr) {
+        // Pinned alloc may return nullptr on devices without host-visible memory; fallback to CPU buffer
+        GGML_LOG_WARN("ggml_vulkan: Pinned memory returned nullptr, falling back to CPU buffer\n");
+        return ggml_backend_buft_alloc_buffer(ggml_backend_cpu_buffer_type(), size);
+    }
+
     ggml_backend_buffer_t buffer = ggml_backend_cpu_buffer_from_ptr(ptr, size);
     buffer->buft = buft;
     buffer->iface.free_buffer = ggml_backend_vk_host_buffer_free_buffer;
