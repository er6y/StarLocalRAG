package com.example.starlocalrag;

import android.content.Context;
import android.util.Log;

import ai.onnxruntime.OnnxTensor;
import ai.onnxruntime.OrtEnvironment;
import ai.onnxruntime.OrtException;
import ai.onnxruntime.OrtSession;

import com.example.starlocalrag.api.TokenizerManager;
import com.example.starlocalrag.GlobalStopManager;

import java.io.File;
import java.nio.FloatBuffer;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicBoolean;

/**
 * é‡æ’æ¨¡å‹å¤„ç†å™¨
 * æ”¯æŒONNXæ ¼å¼çš„Cross-Encoderé‡æ’æ¨¡å‹ï¼Œå¦‚bge-reranker-m3
 */
public class RerankerModelHandler {
    private static final String TAG = "StarLocalRAG_RerankerModel";
    private static final int MAX_SEQUENCE_LENGTH = 512; // æœ€å¤§åºåˆ—é•¿åº¦
    private static final int MAX_BATCH_SIZE = 8; // æ‰¹å¤„ç†å¤§å°ï¼Œé¿å…å†…å­˜è¿‡å¤§
    
    // ONNXä¼šè¯çŠ¶æ€å¸¸é‡
    private static final int SESSION_STATE_NONE = 0;      // æœªåˆå§‹åŒ–
    private static final int SESSION_STATE_LOADING = 1;   // æ­£åœ¨åŠ è½½
    private static final int SESSION_STATE_READY = 2;     // å·²å°±ç»ª
    private static final int SESSION_STATE_ERROR = 3;     // é”™è¯¯çŠ¶æ€
    
    // ä¼šè¯é‡è¯•ç›¸å…³å¸¸é‡
    private static final int MAX_SESSION_RETRY = 3;       // æœ€å¤§é‡è¯•æ¬¡æ•°
    private static final long SESSION_RETRY_DELAY_MS = 500; // é‡è¯•é—´éš”
    
    private final Context context;
    private final String modelPath;
    private OrtEnvironment environment;
    private OrtSession session;
    private final AtomicBoolean isInitialized = new AtomicBoolean(false);
    private final AtomicBoolean isLoading = new AtomicBoolean(false);
    
    // ä¼šè¯çŠ¶æ€ç®¡ç†å˜é‡
    private final Object sessionLock = new Object();      // ä¼šè¯é”
    private int sessionState = SESSION_STATE_NONE;        // å½“å‰ä¼šè¯çŠ¶æ€
    private int sessionRetryCount = 0;                    // å½“å‰é‡è¯•æ¬¡æ•°
    private long lastSessionCheckTime = 0;                // ä¸Šæ¬¡ä¼šè¯æ£€æŸ¥æ—¶é—´
    
    // TokenizerManagerå®ä¾‹ - ä¸å†ç¼“å­˜ï¼Œæ¯æ¬¡åŠ¨æ€è·å–
    // private TokenizerManager tokenizerManager; // ç§»é™¤ç¼“å­˜çš„å®ä¾‹
    
    // æ¨¡å‹è¾“å…¥è¾“å‡ºåç§°ï¼ˆæ ¹æ®å…·ä½“æ¨¡å‹è°ƒæ•´ï¼‰
    private static final String INPUT_IDS = "input_ids";
    private static final String ATTENTION_MASK = "attention_mask";
    private static final String TOKEN_TYPE_IDS = "token_type_ids";
    private static final String OUTPUT_LOGITS = "logits";
    
    /**
     * é‡æ’ç»“æœç±»
     */
    public static class RerankResult implements Comparable<RerankResult> {
        public final String text;
        public final float score;
        public final int originalIndex;
        
        public RerankResult(String text, float score, int originalIndex) {
            this.text = text;
            this.score = score;
            this.originalIndex = originalIndex;
        }
        
        @Override
        public int compareTo(RerankResult other) {
            // æŒ‰åˆ†æ•°é™åºæ’åˆ—
            return Float.compare(other.score, this.score);
        }
    }
    
    public RerankerModelHandler(Context context, String modelPath) {
        this.context = context;
        this.modelPath = modelPath;
    }
    
    /**
     * åˆå§‹åŒ–æ¨¡å‹
     */
    public boolean initialize() {
        if (isInitialized.get()) {
            return true;
        }
        
        synchronized (sessionLock) {
            // åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼
            if (isInitialized.get()) {
                return true;
            }
            
            if (isLoading.get()) {
                LogManager.logW(TAG, "Model is loading, please wait");
                return false;
            }
            
            isLoading.set(true);
            sessionState = SESSION_STATE_LOADING;
            LogManager.logD(TAG, "Session state changed: " + sessionState + " (loading started)");
        
        try {
            LogManager.logI(TAG, "Starting to initialize reranker model: " + modelPath);
            
            // Check if model file exists
            File modelFile = new File(modelPath);
            if (!modelFile.exists()) {
                LogManager.logE(TAG, "Reranker model file does not exist: " + modelPath);
                return false;
            }
            
            // æ‰“å°æ¨¡å‹æ–‡ä»¶è¯¦ç»†ä¿¡æ¯
            long fileSize = modelFile.length();
            LogManager.logI(TAG, "Model file size: " + (fileSize / 1024 / 1024) + " MB");
            LogManager.logI(TAG, "Model file readable: " + modelFile.canRead());
            LogManager.logI(TAG, "Model file absolute path: " + modelFile.getAbsolutePath());
            
            // æ£€æŸ¥å¯ç”¨å†…å­˜
            Runtime runtime = Runtime.getRuntime();
            long maxMemory = runtime.maxMemory();
            long totalMemory = runtime.totalMemory();
            long freeMemory = runtime.freeMemory();
            long usedMemory = totalMemory - freeMemory;
            LogManager.logI(TAG, "Memory status - Max: " + (maxMemory / 1024 / 1024) + "MB, " +
                           "Used: " + (usedMemory / 1024 / 1024) + "MB, " +
                           "Free: " + (freeMemory / 1024 / 1024) + "MB");
            
            // Create ONNX environment
            LogManager.logI(TAG, "Creating ONNX environment...");
            environment = OrtEnvironment.getEnvironment();
            LogManager.logI(TAG, "ONNX environment created successfully");
            
            // Create session options
            LogManager.logI(TAG, "Creating session options...");
            OrtSession.SessionOptions sessionOptions = new OrtSession.SessionOptions();
            
            // è®¾ç½®çº¿ç¨‹æ•°ï¼ˆä»ConfigManagerè·å–é…ç½®ï¼‰
            int threadCount = ConfigManager.getThreads(context);
            LogManager.logI(TAG, "Setting thread count: " + threadCount);
            sessionOptions.setIntraOpNumThreads(threadCount);
            sessionOptions.setInterOpNumThreads(threadCount);
            
            // è®¾ç½®å†…å­˜ä¼˜åŒ–é€‰é¡¹
            LogManager.logI(TAG, "Setting memory optimization options...");
            sessionOptions.setMemoryPatternOptimization(true);
            
            // è®¾ç½®æ‰§è¡Œæ¨¡å¼ä¸ºé¡ºåºæ‰§è¡Œï¼Œé¿å…å¹¶å‘é—®é¢˜
            LogManager.logI(TAG, "Setting execution mode to sequential...");
            sessionOptions.setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL);
            
            // è®¾ç½®å…¶ä»–é€‰é¡¹
            LogManager.logI(TAG, "Session options setup completed");
            
            // Load model
            LogManager.logI(TAG, "Starting to load ONNX model...");
            LogManager.logI(TAG, "Before session creation - Thread: " + Thread.currentThread().getName());
            LogManager.logI(TAG, "Before session creation - Timestamp: " + System.currentTimeMillis());
            
            session = environment.createSession(modelPath, sessionOptions);
            
            LogManager.logI(TAG, "ONNX model loaded successfully");
            LogManager.logI(TAG, "After session creation - Timestamp: " + System.currentTimeMillis());
            
            // æ‰“å°æ¨¡å‹ä¿¡æ¯
            LogManager.logI(TAG, "Model input count: " + session.getInputNames().size());
            LogManager.logI(TAG, "Model output count: " + session.getOutputNames().size());
            LogManager.logI(TAG, "Model input names: " + session.getInputNames());
            LogManager.logI(TAG, "Model output names: " + session.getOutputNames());
            
            // åˆå§‹åŒ–TokenizerManager - ä¸å†ç¼“å­˜å®ä¾‹ï¼Œæ¯æ¬¡åŠ¨æ€è·å–
            //LogManager.logI(TAG, "å¼€å§‹åˆå§‹åŒ–TokenizerManager...");
            try {
                TokenizerManager tempTokenizerManager = TokenizerManager.getInstance(context);
                
                // è·å–tokenizer.jsonæ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
                File modelDir = modelFile.getParentFile();
                
                if (modelDir != null && modelDir.exists()) {
                    LogManager.logI(TAG, "Trying to initialize tokenizer from model directory: " + modelDir.getAbsolutePath());
                    boolean tokenizerSuccess = tempTokenizerManager.initialize(modelDir);
                    
                    if (tokenizerSuccess) {
                        LogManager.logI(TAG, "TokenizerManageråˆå§‹åŒ–æˆåŠŸï¼Œå°†ä½¿ç”¨åŠ¨æ€è·å–æ–¹å¼");
                        //LogManager.logI(TAG, "Tokenizerç‰¹æ®Štokenæ•°é‡: " + tempTokenizerManager.getSpecialTokensSize());
                    } else {
                        LogManager.logW(TAG, "TokenizerManager initialization failed, will use simplified tokenizer");
                    }
                } else {
                    LogManager.logW(TAG, "Unable to get model directory, will use simplified tokenizer");
                    // ä¸å†è®¾ç½®æˆå‘˜å˜é‡ä¸ºnullï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨åŠ¨æ€è·å–æ–¹å¼
                }
            } catch (Exception e) {
                LogManager.logE(TAG, "TokenizerManager initialization exception: " + e.getMessage(), e);
                // ä¸å†è®¾ç½®æˆå‘˜å˜é‡ä¸ºnullï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨åŠ¨æ€è·å–æ–¹å¼
            }
            
            isInitialized.set(true);
            sessionState = SESSION_STATE_READY;
            sessionRetryCount = 0; // é‡ç½®é‡è¯•è®¡æ•°
            //LogManager.logI(TAG, "Reranker model initialization successful");
            //LogManager.logD(TAG, "Session state changed: " + sessionState + " (initialization successful)");
            
            return true;
            
        } catch (OutOfMemoryError e) {
            LogManager.logE(TAG, "Reranker model initialization failed - Out of memory");
            LogManager.logE(TAG, "Exception type: " + e.getClass().getSimpleName());
            LogManager.logE(TAG, "Exception message: " + e.getMessage());
            LogManager.logE(TAG, "Exception details: ", e);
            
            sessionState = SESSION_STATE_ERROR;
            LogManager.logD(TAG, "Session state changed: " + sessionState + " (out of memory error)");
            
            // å¼ºåˆ¶åƒåœ¾å›æ”¶
            System.gc();
            
            cleanup();
            return false;
        } catch (Exception e) {
            LogManager.logE(TAG, "Reranker model initialization failed");
            LogManager.logE(TAG, "Exception type: " + e.getClass().getSimpleName());
            LogManager.logE(TAG, "Exception message: " + e.getMessage());
            LogManager.logE(TAG, "Exception details: ", e);
            
            sessionState = SESSION_STATE_ERROR;
            LogManager.logD(TAG, "Session state changed: " + sessionState + " (initialization exception)");
            
            // æ‰“å°æ›´å¤šè°ƒè¯•ä¿¡æ¯
            if (e.getCause() != null) {
                LogManager.logE(TAG, "Root cause: " + e.getCause().getClass().getSimpleName() + ": " + e.getCause().getMessage());
            }
            
            // æ£€æŸ¥æ˜¯å¦æ˜¯å†…å­˜ç›¸å…³é—®é¢˜
            if (e.getMessage() != null && e.getMessage().toLowerCase().contains("memory")) {
                LogManager.logE(TAG, "Possibly memory-related failure");
                // å¼ºåˆ¶åƒåœ¾å›æ”¶
                System.gc();
            }
            
            // æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶è®¿é—®é—®é¢˜
            if (e.getMessage() != null && 
                (e.getMessage().toLowerCase().contains("file") || 
                 e.getMessage().toLowerCase().contains("path") ||
                 e.getMessage().toLowerCase().contains("access"))) {
                LogManager.logE(TAG, "Possibly file access permission issue");
            }
            
            cleanup();
            return false;
        } finally {
            isLoading.set(false);
        }
        } // ç»“æŸsynchronizedå—
    }
    
    /**
     * é‡æ’è¿›åº¦å›è°ƒæ¥å£
     */
    public interface RerankProgressCallback {
        void onRerankProgress(int processedCount, int totalCount, double score);
    }
    
    /**
     * å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’
     * @param query æŸ¥è¯¢æ–‡æœ¬
     * @param documents å¾…é‡æ’çš„æ–‡æ¡£åˆ—è¡¨
     * @param topK è¿”å›å‰Kä¸ªç»“æœ
     * @return é‡æ’åçš„ç»“æœåˆ—è¡¨
     */
    public List<RerankResult> rerank(String query, List<String> documents, int topK) {
        return rerank(query, documents, topK, null);
    }
    
    /**
     * å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
     * @param query æŸ¥è¯¢æ–‡æœ¬
     * @param documents å¾…é‡æ’çš„æ–‡æ¡£åˆ—è¡¨
     * @param topK è¿”å›å‰Kä¸ªç»“æœ
     * @param progressCallback è¿›åº¦å›è°ƒ
     * @return é‡æ’åçš„ç»“æœåˆ—è¡¨
     */
    public List<RerankResult> rerank(String query, List<String> documents, int topK, RerankProgressCallback progressCallback) {
        // ç«‹å³è¾“å‡ºæ—¥å¿—ï¼Œç¡®è®¤æ–¹æ³•è¢«è°ƒç”¨
        LogManager.logI(TAG, "=== RERANK METHOD EXECUTION STARTED ===");
        
        // æ£€æŸ¥å…¨å±€åœæ­¢æ ‡å¿—
        if (GlobalStopManager.isGlobalStopRequested()) {
            LogManager.logD(TAG, "æ£€æµ‹åˆ°å…¨å±€åœæ­¢æ ‡å¿—ï¼Œä¸­æ–­é‡æ’åºæ“ä½œ");
            return convertToRerankResults(documents); // è¿”å›åŸå§‹é¡ºåº
        }
        
        //LogManager.logI(TAG, "Query text: " + (query != null ? query.substring(0, Math.min(50, query.length())) + "..." : "null"));
        //LogManager.logI(TAG, "Document count: " + (documents != null ? documents.size() : 0));
        //LogManager.logI(TAG, "topK: " + topK);
        //LogManager.logI(TAG, "Model initialization status: " + isInitialized.get());
        
        // é¦–å…ˆæ£€æŸ¥TokenizerManagerçŠ¶æ€
        LogManager.logI(TAG, "ğŸ” æ£€æŸ¥TokenizerManagerçŠ¶æ€...");
        String statusReport = checkTokenizerManagerStatus();
        LogManager.logI(TAG, statusReport);
        
        // éªŒè¯TokenizerManageræ˜¯å¦å¯ç”¨
        if (getCurrentTokenizerManager() == null) {
            LogManager.logW(TAG, "âš ï¸ TokenizerManagerä¸å¯ç”¨ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–...");
            if (!validateAndReinitializeTokenizer()) {
                LogManager.logE(TAG, "âŒ TokenizerManageré‡æ–°åˆå§‹åŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹é¡ºåº");
                return convertToRerankResults(documents);
            }
            LogManager.logI(TAG, "âœ… TokenizerManageré‡æ–°åˆå§‹åŒ–æˆåŠŸ");
        }
        
        if (!isInitialized.get()) {
            LogManager.logE(TAG, "Reranker model not initialized");
            return convertToRerankResults(documents); // è¿”å›åŸå§‹é¡ºåº
        }
        
        // æ£€æŸ¥å¹¶æ¢å¤ä¼šè¯çŠ¶æ€
        if (!checkAndRecoverSession()) {
            LogManager.logE(TAG, "Reranker model session unavailable, returning original order");
            return convertToRerankResults(documents);
        }
        
        if (documents == null || documents.isEmpty()) {
            LogManager.logW(TAG, "Document list is empty");
            return new ArrayList<>();
        }
        
        if (query == null || query.trim().isEmpty()) {
            LogManager.logW(TAG, "Query text is empty");
            return convertToRerankResults(documents);
        }
        
        try {
            //LogManager.logD(TAG, "Starting reranking, query: " + query.substring(0, Math.min(50, query.length())) + 
            //               "..., document count: " + documents.size());
            
            List<RerankResult> results = new ArrayList<>();
            
            // åˆ†æ‰¹å¤„ç†ä»¥é¿å…å†…å­˜è¿‡å¤§
            for (int i = 0; i < documents.size(); i += MAX_BATCH_SIZE) {
                // åœ¨æ¯ä¸ªæ‰¹æ¬¡å¼€å§‹å‰æ£€æŸ¥åœæ­¢æ ‡å¿—
                if (GlobalStopManager.isGlobalStopRequested()) {
                    LogManager.logD(TAG, "æ£€æµ‹åˆ°å…¨å±€åœæ­¢æ ‡å¿—ï¼Œä¸­æ–­é‡æ’åºæ‰¹å¤„ç†");
                    break;
                }
                
                int endIndex = Math.min(i + MAX_BATCH_SIZE, documents.size());
                List<String> batch = documents.subList(i, endIndex);
                
                List<RerankResult> batchResults = processBatch(query, batch, i, progressCallback);
                results.addAll(batchResults);
            }
            
            // æŒ‰åˆ†æ•°æ’åº
            Collections.sort(results);
            
            // è¿”å›å‰topKä¸ªç»“æœ
            int resultSize = Math.min(topK, results.size());
            List<RerankResult> topResults = results.subList(0, resultSize);
            
            LogManager.logD(TAG, "Reranking completed, returning top " + resultSize + " results");
            return topResults;
            
        } catch (Exception e) {
            LogManager.logE(TAG, "Error occurred during reranking process");
            LogManager.logE(TAG, "Exception type: " + e.getClass().getSimpleName());
            LogManager.logE(TAG, "Exception message: " + e.getMessage());
            LogManager.logE(TAG, "Query text: " + (query != null ? query.substring(0, Math.min(100, query.length())) : "null"));
            LogManager.logE(TAG, "Document count: " + (documents != null ? documents.size() : 0));
            LogManager.logE(TAG, "Exception details: ", e);
            
            if (e.getCause() != null) {
                LogManager.logE(TAG, "Root cause: " + e.getCause().getClass().getSimpleName() + ": " + e.getCause().getMessage());
            }
            
            return convertToRerankResults(documents); // è¿”å›åŸå§‹é¡ºåº
        }
    }
    
    /**
     * å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„æ–‡æ¡£
     */
    private List<RerankResult> processBatch(String query, List<String> documents, int startIndex) throws OrtException {
        return processBatch(query, documents, startIndex, null);
    }
    
    /**
     * å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„æ–‡æ¡£ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
     */
    private List<RerankResult> processBatch(String query, List<String> documents, int startIndex, RerankProgressCallback progressCallback) throws OrtException {
        List<RerankResult> results = new ArrayList<>();
        
        //LogManager.logI(TAG, "Starting batch processing, document count: " + documents.size() + ", start index: " + startIndex);
        
        for (int i = 0; i < documents.size(); i++) {
            // åœ¨å¤„ç†æ¯ä¸ªæ–‡æ¡£å‰æ£€æŸ¥åœæ­¢æ ‡å¿—
            if (GlobalStopManager.isGlobalStopRequested()) {
                LogManager.logD(TAG, "æ£€æµ‹åˆ°å…¨å±€åœæ­¢æ ‡å¿—ï¼Œä¸­æ–­æ–‡æ¡£å¤„ç†");
                break;
            }
            
            long docStartTime = System.currentTimeMillis();
            int globalIndex = startIndex + i;
            
            LogManager.logI(TAG, "=== Starting document processing " + (i + 1) + "/" + documents.size() + " (global index: " + globalIndex + ") ===");
            
            String document = documents.get(i);
            if (document == null || document.trim().isEmpty()) {
                LogManager.logW(TAG, "Skipping empty document " + globalIndex);
                continue;
            }
            
            // æ„å»ºè¾“å…¥æ–‡æœ¬ï¼ˆæ ‡è®°è¾“å…¥æ ¼å¼ï¼š[Q] query [SEP] [D] document [SEP]ï¼‰
            String inputText = "[Q] " + query + " [SEP] [D] " + document + " [SEP]";
            //LogManager.logI(TAG, "Building tagged input format text:");
            //LogManager.logI(TAG, "  - Query length: " + query.length() + " characters");
            //LogManager.logI(TAG, "  - Document length: " + document.length() + " characters");
            //LogManager.logI(TAG, "  - Combined total length: " + inputText.length() + " characters");
            //LogManager.logI(TAG, "  - Format: [Q] query [SEP] [D] document [SEP]");
            LogManager.logI(TAG, "Input text preview: " + inputText.substring(0, Math.min(150, inputText.length())) + "...");
            
            //LogManager.logW(TAG, "ğŸ” Performance analysis: Key differences between reranking vs embedding:");
            //LogManager.logW(TAG, "  1. Embedding model: Only needs to process single document, outputs fixed-dimension vector");
            //LogManager.logW(TAG, "  2. Reranking model: Needs to process query+document combination, each document requires separate inference");
            //LogManager.logW(TAG, "  3. Current document count: " + documents.size() + ", meaning " + documents.size() + " independent inferences needed");
            
            // å¼€å§‹æ–‡æœ¬åˆ†è¯å¤„ç†
            long tokenizeStartTime = System.currentTimeMillis();
            //LogManager.logI(TAG, "=== Starting TOKENIZATION for document " + (i+1) + "/" + documents.size() + " ===");
            //LogManager.logI(TAG, "ğŸ”¤ Input text statistics:");
            //LogManager.logI(TAG, "  - Original query length: " + query.length() + " characters");
            //LogManager.logI(TAG, "  - Original document length: " + document.length() + " characters");
            //LogManager.logI(TAG, "  - Combined text length: " + inputText.length() + " characters");
            //LogManager.logI(TAG, "  - Estimated token count: ~" + (inputText.length() / 4) + " (estimate)");
            //LogManager.logI(TAG, "ğŸ¯ Starting tokenizeInput method call...");
            
            Map<String, OnnxTensor> inputs;
            try {
                inputs = tokenizeInput(inputText);
                long tokenizeTime = System.currentTimeMillis() - tokenizeStartTime;
                //LogManager.logI(TAG, "âœ… TOKENIZATION completed, total time: " + tokenizeTime + "ms");
                //LogManager.logI(TAG, "ğŸ“Š Output tensor statistics:");
                //LogManager.logI(TAG, "  - Tensor count: " + inputs.size());
                
                // æ‰“å°å¼ é‡ç»´åº¦ä¿¡æ¯
                for (Map.Entry<String, OnnxTensor> entry : inputs.entrySet()) {
                    long[] shape = entry.getValue().getInfo().getShape();
                    //LogManager.logI(TAG, "  - Tensor [" + entry.getKey() + "] dimensions: " + java.util.Arrays.toString(shape));
                    //LogManager.logI(TAG, "  - Tensor [" + entry.getKey() + "] total elements: " + java.util.Arrays.stream(shape).reduce(1, (a, b) -> a * b));
                }
            } catch (Exception e) {
                LogManager.logE(TAG, "âŒ TOKENIZATION failed: " + e.getMessage(), e);
                LogManager.logE(TAG, "Failed input text length: " + inputText.length());
                LogManager.logE(TAG, "Failed input text preview: " + inputText.substring(0, Math.min(100, inputText.length())));
                continue;
            }
            
            try {
                // è¿è¡Œæ¨ç†
                long inferenceStartTime = System.currentTimeMillis();
                //LogManager.logI(TAG, "=== Starting model inference phase ===");
                //LogManager.logI(TAG, "ğŸ§  Inference environment check:");
                //LogManager.logI(TAG, "  - Current thread: " + Thread.currentThread().getName());
                //LogManager.logI(TAG, "  - Session status: " + (session != null ? "valid" : "invalid"));
                //LogManager.logI(TAG, "  - Input tensor count: " + inputs.size());
                //LogManager.logI(TAG, "  - System memory: " + (Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory()) / 1024 / 1024 + "MB / " + Runtime.getRuntime().totalMemory() / 1024 / 1024 + "MB");
                
                // å…³é”®çš„æ¨ç†è°ƒç”¨
                //LogManager.logI(TAG, "ğŸš€ Calling session.run()...");
                LogManager.logI(TAG, "Inference timeout setting: 10 minutes");
                
                // ä½¿ç”¨Futureæ¥å®ç°è¶…æ—¶æœºåˆ¶
                java.util.concurrent.ExecutorService executor = java.util.concurrent.Executors.newSingleThreadExecutor();
                java.util.concurrent.Future<OrtSession.Result> future = executor.submit(() -> {
                    LogManager.logI(TAG, "âš¡ Inference thread starting execution...");
                    //LogManager.logI(TAG, "Inference thread ID: " + Thread.currentThread().getId());
                    OrtSession.Result result = session.run(inputs);
                    LogManager.logI(TAG, "âœ… Inference thread execution completed");
                    return result;
                });
                
                OrtSession.Result output;
                try {
                    // è®¾ç½®10åˆ†é’Ÿè¶…æ—¶
                    output = future.get(600, java.util.concurrent.TimeUnit.SECONDS);
                    // LogManager.logI(TAG, "âœ… session.run() è¿”å›æˆåŠŸ");
                } catch (java.util.concurrent.TimeoutException e) {
                    LogManager.logE(TAG, "â° Inference timeout (10 minutes), canceling task");
                    future.cancel(true);
                    executor.shutdownNow();
                    continue; // è·³è¿‡è¿™ä¸ªæ–‡æ¡£
                } catch (java.util.concurrent.ExecutionException e) {
                    LogManager.logE(TAG, "âŒ Inference execution exception: " + e.getCause().getMessage(), e.getCause());
                    executor.shutdownNow();
                    continue;
                } catch (InterruptedException e) {
                    LogManager.logE(TAG, "ğŸ›‘ Inference interrupted: " + e.getMessage());
                    Thread.currentThread().interrupt();
                    executor.shutdownNow();
                    continue;
                } finally {
                    executor.shutdown();
                }
                
                long inferenceTime = System.currentTimeMillis() - inferenceStartTime;
                // LogManager.logI(TAG, "âœ… Model inference completed, time taken: " + inferenceTime + "ms");
                
                // è·å–logits
                long outputProcessStartTime = System.currentTimeMillis();
                //LogManager.logI(TAG, "=== Starting model output processing ===");
                //LogManager.logI(TAG, "ğŸ“¤ Model output analysis:");
                //LogManager.logI(TAG, "  - Output object type: " + output.getClass().getName());
                //LogManager.logI(TAG, "  - Output key count: " + output.size());
                
                // åˆ—å‡ºæ‰€æœ‰è¾“å‡º
                //LogManager.logI(TAG, "ğŸ“‹ Output tensor information:");
                //LogManager.logI(TAG, "  - Output tensor count: " + output.size());
                for (int j = 0; j < output.size(); j++) {
                    try {
                        OnnxTensor tensor = (OnnxTensor) output.get(j);
                        //LogManager.logI(TAG, "  - Tensor[" + j + "] shape: " + java.util.Arrays.toString(tensor.getInfo().getShape()));
                    } catch (Exception e) {
                        LogManager.logI(TAG, "  - Tensor[" + j + "] retrieval failed: " + e.getMessage());
                    }
                }
                
                //LogManager.logI(TAG, "ğŸ¯ Attempting to get logits tensor (index: 0)...");
                OnnxTensor logitsTensor = null;
                try {
                    logitsTensor = (OnnxTensor) output.get(0);
                } catch (Exception e) {
                    LogManager.logE(TAG, "âŒ Failed to get logits tensor: " + e.getMessage());
                }
                
                if (logitsTensor != null) {
                    //LogManager.logI(TAG, "âœ… Successfully obtained logits tensor");
                    Object logitsValue = logitsTensor.getValue();
                    //LogManager.logI(TAG, "ğŸ“Š Logits detailed information:");
                    //LogManager.logI(TAG, "  - Data type: " + logitsValue.getClass().getName());
                    //LogManager.logI(TAG, "  - Tensor shape: " + java.util.Arrays.toString(logitsTensor.getInfo().getShape()));
                    
                    float score;
                    if (logitsValue instanceof float[][][]) {
                        // ä¸‰ç»´è¾“å‡ºï¼š[batch_size, sequence_length, num_classes]
                        float[][][] logits3D = (float[][][]) logitsValue;
                        //LogManager.logI(TAG, "ğŸ”¢ Detected 3D logits output");
                        //LogManager.logI(TAG, "  - Dimensions: [" + logits3D.length + ", " + 
                        //               (logits3D.length > 0 ? logits3D[0].length : 0) + ", " + 
                        //               (logits3D.length > 0 && logits3D[0].length > 0 ? logits3D[0][0].length : 0) + "]");
                        //LogManager.logI(TAG, "  - Interpretation: [batch_size, sequence_length, num_classes]");
                        
                        // é€šå¸¸å–ç¬¬ä¸€ä¸ªbatchçš„ç¬¬ä¸€ä¸ªtokençš„logits
                        if (logits3D.length > 0 && logits3D[0].length > 0) {
                            //LogManager.logI(TAG, "ğŸ“ˆ Using first batch's first token to calculate score");
                            //LogManager.logI(TAG, "  - Original logits length: " + logits3D[0][0].length);
                            if (logits3D[0][0].length > 0) {
                                //LogManager.logI(TAG, "  - First 5 original logits values: " + java.util.Arrays.toString(java.util.Arrays.copyOf(logits3D[0][0], Math.min(5, logits3D[0][0].length))));
                            }
                            score = calculateRelevanceScore(logits3D[0][0]);
                        } else {
                            LogManager.logW(TAG, "âš ï¸ 3D logits array is empty");
                            score = 0.5f;
                        }
                    } else if (logitsValue instanceof float[][]) {
                        // äºŒç»´è¾“å‡ºï¼š[batch_size, num_classes]
                        float[][] logits2D = (float[][]) logitsValue;
                        //LogManager.logI(TAG, "ğŸ”¢ Detected 2D logits output");
                        //LogManager.logI(TAG, "  - Dimensions: [" + logits2D.length + ", " + 
                        //               (logits2D.length > 0 ? logits2D[0].length : 0) + "]");
                        //LogManager.logI(TAG, "  - Interpretation: [batch_size, num_classes]");
                        
                        if (logits2D.length > 0) {
                            //LogManager.logI(TAG, "ğŸ“ˆ Using first batch to calculate score");
                            //LogManager.logI(TAG, "  - Original logits length: " + logits2D[0].length);
                            if (logits2D[0].length > 0) {
                                //LogManager.logI(TAG, "  - First 5 original logits values: " + java.util.Arrays.toString(java.util.Arrays.copyOf(logits2D[0], Math.min(5, logits2D[0].length))));
                            }
                            score = calculateRelevanceScore(logits2D[0]);
                        } else {
                            LogManager.logW(TAG, "âš ï¸ 2D logits array is empty");
                            score = 0.5f;
                        }
                    } else {
                        LogManager.logE(TAG, "âŒ Unsupported logits output type: " + logitsValue.getClass().getName());
                        score = 0.5f;
                    }
                    
                    //LogManager.logI(TAG, "ğŸ¯ Calculated relevance score: " + score);
                    results.add(new RerankResult(document, score, startIndex + i));
                    
                    // è°ƒç”¨è¿›åº¦å›è°ƒ
                    if (progressCallback != null) {
                        progressCallback.onRerankProgress(i + 1, documents.size(), score);
                    }
                    
                    long outputProcessTime = System.currentTimeMillis() - outputProcessStartTime;
                    LogManager.logI(TAG, "âœ… Document " + globalIndex + " processing completed, score: " + score + ", output processing time: " + outputProcessTime + "ms");
                } else {
                    LogManager.logE(TAG, "âŒ Unable to get logits output tensor");
                    LogManager.logE(TAG, "Possible reasons:");
                    LogManager.logE(TAG, "  1. Output key name mismatch (expected: " + OUTPUT_LOGITS + ")");
                    LogManager.logE(TAG, "  2. Model output format does not meet expectations");
                    LogManager.logE(TAG, "  3. Error occurred during inference");
                }
                
                // æ¸…ç†è¾“å‡º
                output.close();
                
                long totalDocTime = System.currentTimeMillis() - docStartTime;
                //LogManager.logI(TAG, "=== Document " + globalIndex + " total time: " + totalDocTime + "ms ===");
                
            } finally {
                // æ¸…ç†è¾“å…¥å¼ é‡
                for (OnnxTensor tensor : inputs.values()) {
                    tensor.close();
                }
            }
        }
        
        return results;
    }
    
    /**
     * Use TokenizerManager for tokenization
     * If TokenizerManager is unavailable, throw an exception directly
     */
    private Map<String, OnnxTensor> tokenizeInput(String text) throws OrtException {
        long tokenizeStartTime = System.currentTimeMillis();
        
        // é¦–å…ˆå°è¯•è·å–å½“å‰TokenizerManagerå®ä¾‹
        TokenizerManager currentTokenizerManager = getCurrentTokenizerManager();
        
        // å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•éªŒè¯å¹¶é‡æ–°åˆå§‹åŒ–
        if (currentTokenizerManager == null) {
            LogManager.logW(TAG, "TokenizerManagerå®ä¾‹æ— æ•ˆï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–...");
            if (!validateAndReinitializeTokenizer()) {
                throw new IllegalStateException("TokenizerManager not initialized or unavailable, unable to perform tokenization");
            }
            // é‡æ–°è·å–å®ä¾‹
            currentTokenizerManager = getCurrentTokenizerManager();
            if (currentTokenizerManager == null) {
                throw new IllegalStateException("TokenizerManageré‡æ–°åˆå§‹åŒ–åä»ç„¶æ— æ•ˆ");
            }
        }
        
        LogManager.logI(TAG, "âœ… TokenizerManager initialized, using professional tokenizer (dynamic instance with validation)");
        return tokenizeWithTokenizerManager(text, tokenizeStartTime, currentTokenizerManager);
    }
    
    /**
     * Use TokenizerManager for tokenization
     */
    private Map<String, OnnxTensor> tokenizeWithTokenizerManager(String text, long startTime, TokenizerManager tokenizerManager) throws OrtException {
        try {
            LogManager.logI(TAG, "ğŸ”§ === Using TokenizerManager for professional tokenization ===");
            
            // ä½¿ç”¨TokenizerManagerè¿›è¡Œtokenization
            long tokenizeTime = System.currentTimeMillis();
            //LogManager.logI(TAG, "ğŸ“ Calling TokenizerManager.tokenize()...");
            //LogManager.logI(TAG, "  - Input text length: " + text.length());
            //LogManager.logI(TAG, "  - TokenizerManager instance: " + tokenizerManager.getClass().getSimpleName());
            
            long[][] tokenIds = tokenizerManager.tokenize(text);
            long tokenizeDuration = System.currentTimeMillis() - tokenizeTime;
            
            //LogManager.logI(TAG, "âœ… TokenizerManager tokenization completed");
            //LogManager.logI(TAG, "ğŸ“Š Tokenization result statistics:");
            //LogManager.logI(TAG, "  - Tokenization time: " + tokenizeDuration + "ms");
            //LogManager.logI(TAG, "  - Token sequence dimensions: [" + tokenIds.length + ", " + tokenIds[0].length + "]");
            //LogManager.logI(TAG, "  - Generated token count: " + tokenIds[0].length);
            //LogManager.logI(TAG, "  - Compression ratio: " + String.format("%.2f", (double)text.length() / tokenIds[0].length) + " characters/token");
            //LogManager.logI(TAG, "  - First 10 token IDs: " + java.util.Arrays.toString(
            //    java.util.Arrays.copyOf(tokenIds[0], Math.min(10, tokenIds[0].length))));
            if (tokenIds[0].length > 10) {
                //LogManager.logI(TAG, "  - Last 5 token IDs: " + java.util.Arrays.toString(
                //    java.util.Arrays.copyOfRange(tokenIds[0], Math.max(0, tokenIds[0].length - 5), tokenIds[0].length)));
            }
            
            // Handle sequence length
            //LogManager.logI(TAG, "ğŸ” Checking sequence length limits...");
            int actualLength = tokenIds[0].length;
            if (actualLength > MAX_SEQUENCE_LENGTH) {
                LogManager.logW(TAG, "âš ï¸ Sequence length exceeds limit!");
                LogManager.logW(TAG, "  - Original length: " + actualLength);
                LogManager.logW(TAG, "  - Maximum allowed: " + MAX_SEQUENCE_LENGTH);
                LogManager.logW(TAG, "  - Performing truncation...");
                long[][] truncatedTokenIds = new long[1][MAX_SEQUENCE_LENGTH];
                System.arraycopy(tokenIds[0], 0, truncatedTokenIds[0], 0, MAX_SEQUENCE_LENGTH);
                tokenIds = truncatedTokenIds;
                actualLength = MAX_SEQUENCE_LENGTH;
                LogManager.logI(TAG, "âœ… Truncation completed, new length: " + actualLength);
            } else {
                LogManager.logI(TAG, "âœ… Sequence length meets requirements: " + actualLength + " <= " + MAX_SEQUENCE_LENGTH);
            }
            
            // Create attention mask and token type ids
            long tensorCreateTime = System.currentTimeMillis();
            //LogManager.logI(TAG, "ğŸ­ Creating attention mask and token type ids...");
            
            long[][] attentionMask = new long[1][actualLength];
            long[][] tokenTypeIds = new long[1][actualLength];
            
            // Fill attention mask (all positions are 1, indicating valid tokens)
            for (int i = 0; i < actualLength; i++) {
                attentionMask[0][i] = 1;
                tokenTypeIds[0][i] = 0; // For tagged input format, may need to set different token types based on [Q], [SEP], [D] positions
            }
            
            //LogManager.logI(TAG, "  - attention mask length: " + actualLength);
            //LogManager.logI(TAG, "  - All values set to: 1 (indicating all tokens need attention)");
            //LogManager.logI(TAG, "  - token type IDs length: " + actualLength);
            //LogManager.logI(TAG, "  - All values set to: 0 (indicating single sentence type)");
            
            // Create ONNX tensors
            LogManager.logI(TAG, "ğŸ”„ Converting to ONNX tensors...");
            Map<String, OnnxTensor> inputs = new HashMap<>();
            
            //LogManager.logI(TAG, "  - Creating input_ids tensor: [1, " + actualLength + "]");
            inputs.put(INPUT_IDS, OnnxTensor.createTensor(environment, tokenIds));
            
            //LogManager.logI(TAG, "  - Creating attention_mask tensor: [1, " + actualLength + "]");
            inputs.put(ATTENTION_MASK, OnnxTensor.createTensor(environment, attentionMask));
            
            //LogManager.logI(TAG, "  - Creating token_type_ids tensor: [1, " + actualLength + "]");
            inputs.put(TOKEN_TYPE_IDS, OnnxTensor.createTensor(environment, tokenTypeIds));
            
            long tensorCreateDuration = System.currentTimeMillis() - tensorCreateTime;
            long totalDuration = System.currentTimeMillis() - startTime;
            
            //LogManager.logI(TAG, "âœ… TokenizerManager tokenization process completed");
            //LogManager.logI(TAG, "ğŸ“ˆ Performance statistics:");
            //LogManager.logI(TAG, "  - Total time: " + totalDuration + "ms");
            //LogManager.logI(TAG, "  - Pure tokenization time: " + tokenizeDuration + "ms");
            //LogManager.logI(TAG, "  - Tensor creation time: " + tensorCreateDuration + "ms");
            //LogManager.logI(TAG, "  - Output tensor count: " + inputs.size());
            
            return inputs;
            
        } catch (Exception e) {
            LogManager.logE(TAG, "âŒ TokenizerManager tokenization failed: " + e.getMessage(), e);
            
            // æ£€æŸ¥æ˜¯å¦æ˜¯åˆ†è¯å™¨æœªåˆå§‹åŒ–çš„é”™è¯¯
            if (e.getMessage() != null && e.getMessage().contains("åˆ†è¯å™¨æœªåˆå§‹åŒ–")) {
                LogManager.logW(TAG, "æ£€æµ‹åˆ°åˆ†è¯å™¨æœªåˆå§‹åŒ–é”™è¯¯ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºTokenizerManagerè¢«é‡ç½®å¯¼è‡´çš„");
                LogManager.logW(TAG, "å»ºè®®æ£€æŸ¥TokenizerManagerçš„çŠ¶æ€ç®¡ç†å’Œé‡ç½®é€»è¾‘");
            }
            
            // æ£€æŸ¥æ˜¯å¦æ˜¯ONNX Runtimeç›¸å…³é”™è¯¯
            if (e.getMessage() != null && e.getMessage().contains("OrtException")) {
                LogManager.logW(TAG, "æ£€æµ‹åˆ°ONNX Runtimeé”™è¯¯ï¼Œå¯èƒ½ä¸è¾“å…¥å¼ é‡ç»´åº¦æœ‰å…³");
            }
            
            throw new OrtException("Tokenization processing failed: " + e.getMessage());
        }
    }
    

    
    /**
     * è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
     */
    private float calculateRelevanceScore(float[] logits) {
        LogManager.logI(TAG, "ğŸ§® === Starting relevance score calculation ===");
        // LogManager.logI(TAG, "ğŸ“Š Input logits analysis:");
        
        if (logits == null || logits.length == 0) {
            LogManager.logW(TAG, "âš ï¸ logits is empty, returning default score 0.5");
            return 0.5f;
        }
        
        // å‘é‡å¼‚å¸¸æ£€æµ‹å’Œä¿®å¤
        try {
            VectorAnomalyHandler.AnomalyResult anomalyResult = VectorAnomalyHandler.detectAnomalies(logits, -1);
            if (anomalyResult.isAnomalous) {
                LogManager.logW(TAG, "æ£€æµ‹åˆ°logitså‘é‡å¼‚å¸¸ï¼Œå°è¯•ä¿®å¤");
                logits = VectorAnomalyHandler.repairVector(logits, anomalyResult.type);
                
                // å¯¹ä¿®å¤åçš„å‘é‡è¿›è¡Œæœ€ç»ˆéªŒè¯
                VectorAnomalyHandler.AnomalyResult verifyResult = VectorAnomalyHandler.detectAnomalies(logits, -1);
                if (verifyResult.isAnomalous) {
                    LogManager.logW(TAG, "logitså‘é‡ä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ•°");
                    return 0.5f;
                }
            }
        } catch (Exception e) {
            LogManager.logE(TAG, "logitså‘é‡å¼‚å¸¸å¤„ç†å¤±è´¥: " + e.getMessage());
            return 0.5f;
        }
        
        LogManager.logI(TAG, "  - logits length: " + logits.length);
        // LogManager.logI(TAG, "  - All logits values: " + java.util.Arrays.toString(logits));
        
        // For binary classification tasks, sigmoid activation function is typically used
        // If logits has only one value, apply sigmoid directly
        if (logits.length == 1) {
            LogManager.logI(TAG, "ğŸ”¢ Detected single-value logits mode");
            LogManager.logI(TAG, "  - Original logit value: " + logits[0]);
            float score = sigmoid(logits[0]);
            LogManager.logI(TAG, "  - Applied sigmoid function: sigmoid(" + logits[0] + ") = " + score);
            LogManager.logI(TAG, "âœ… Final score: " + score);
            return score;
        }
        
        // If there are multiple logits values, softmax or other processing may be needed
        // Here we assume the second value is the positive class logits (adjust according to specific model)
        if (logits.length >= 2) {
            LogManager.logI(TAG, "ğŸ”¢ Detected multi-value logits mode");
            LogManager.logI(TAG, "  - Negative class logit (index 0): " + logits[0]);
            LogManager.logI(TAG, "  - Positive class logit (index 1): " + logits[1]);
            
            float positiveLogit = logits[1];
            LogManager.logI(TAG, "  - Using positive class logit to calculate score: " + positiveLogit);
            float score = sigmoid(positiveLogit);
            LogManager.logI(TAG, "  - Applied sigmoid function: sigmoid(" + positiveLogit + ") = " + score);
            
            // Also calculate softmax as reference
            float[] softmaxScores = softmax(new float[]{logits[0], logits[1]});
            LogManager.logI(TAG, "  - Reference softmax scores: [" + softmaxScores[0] + ", " + softmaxScores[1] + "]");
            LogManager.logI(TAG, "  - Softmax positive class probability: " + softmaxScores[1]);
            
            LogManager.logI(TAG, "âœ… Final score: " + score);
            return score;
        }
        
        LogManager.logW(TAG, "âš ï¸ Unknown logits format, returning default score 0.5");
        return 0.5f;
    }
    
    /**
     * Sigmoidæ¿€æ´»å‡½æ•°ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰
     */
    private float sigmoid(float x) {
        // æ£€æŸ¥è¾“å…¥å¼‚å¸¸
        if (Float.isNaN(x) || Float.isInfinite(x)) {
            LogManager.logW(TAG, "Sigmoidè¾“å…¥å¼‚å¸¸: " + x + "ï¼Œè¿”å›é»˜è®¤å€¼0.5");
            return 0.5f;
        }
        
        // é˜²æ­¢æ•°å€¼æº¢å‡º
        if (x > 700) {
            return 1.0f; // exp(-700) æ¥è¿‘ 0ï¼Œsigmoid æ¥è¿‘ 1
        } else if (x < -700) {
            return 0.0f; // exp(700) æ¥è¿‘æ— ç©·å¤§ï¼Œsigmoid æ¥è¿‘ 0
        }
        
        try {
            float result = (float) (1.0 / (1.0 + Math.exp(-x)));
            
            // æ£€æŸ¥ç»“æœå¼‚å¸¸
            if (Float.isNaN(result) || Float.isInfinite(result)) {
                LogManager.logW(TAG, "Sigmoidè®¡ç®—ç»“æœå¼‚å¸¸: " + result + "ï¼Œè¿”å›é»˜è®¤å€¼0.5");
                return 0.5f;
            }
            
            // ç¡®ä¿ç»“æœåœ¨[0,1]èŒƒå›´å†…
            return Math.max(0.0f, Math.min(1.0f, result));
        } catch (Exception e) {
            LogManager.logE(TAG, "Sigmoidè®¡ç®—å¼‚å¸¸: " + e.getMessage());
            return 0.5f;
        }
    }
    
    /**
     * Softmaxå‡½æ•°ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰
     */
    private float[] softmax(float[] logits) {
        if (logits == null || logits.length == 0) {
            LogManager.logW(TAG, "Softmaxè¾“å…¥ä¸ºç©ºï¼Œè¿”å›é»˜è®¤ç»“æœ");
            return new float[]{0.5f};
        }
        
        float[] result = new float[logits.length];
        
        try {
            // æ£€æŸ¥è¾“å…¥å¼‚å¸¸
            for (int i = 0; i < logits.length; i++) {
                if (Float.isNaN(logits[i]) || Float.isInfinite(logits[i])) {
                    LogManager.logW(TAG, "Softmaxè¾“å…¥åŒ…å«å¼‚å¸¸å€¼: " + logits[i] + "ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ");
                    // è¿”å›å‡åŒ€åˆ†å¸ƒ
                    float uniformValue = 1.0f / logits.length;
                    for (int j = 0; j < result.length; j++) {
                        result[j] = uniformValue;
                    }
                    return result;
                }
            }
            
            // æ‰¾åˆ°æœ€å¤§å€¼ä»¥é˜²æ­¢æ•°å€¼æº¢å‡º
            float maxLogit = logits[0];
            for (int i = 1; i < logits.length; i++) {
                if (logits[i] > maxLogit) {
                    maxLogit = logits[i];
                }
            }
            
            // è®¡ç®—expå€¼ï¼ˆå‡å»æœ€å¤§å€¼é˜²æ­¢æº¢å‡ºï¼‰
            float sum = 0.0f;
            for (int i = 0; i < logits.length; i++) {
                float expValue = (float) Math.exp(logits[i] - maxLogit);
                if (Float.isNaN(expValue) || Float.isInfinite(expValue)) {
                    LogManager.logW(TAG, "Softmax expè®¡ç®—å¼‚å¸¸ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ");
                    float uniformValue = 1.0f / logits.length;
                    for (int j = 0; j < result.length; j++) {
                        result[j] = uniformValue;
                    }
                    return result;
                }
                result[i] = expValue;
                sum += expValue;
            }
            
            // æ£€æŸ¥sumæ˜¯å¦å¼‚å¸¸
            if (sum <= 0 || Float.isNaN(sum) || Float.isInfinite(sum)) {
                LogManager.logW(TAG, "Softmax sumå¼‚å¸¸: " + sum + "ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ");
                float uniformValue = 1.0f / logits.length;
                for (int j = 0; j < result.length; j++) {
                    result[j] = uniformValue;
                }
                return result;
            }
            
            // å½’ä¸€åŒ–
            for (int i = 0; i < result.length; i++) {
                result[i] /= sum;
                
                // æ£€æŸ¥å½’ä¸€åŒ–ç»“æœ
                if (Float.isNaN(result[i]) || Float.isInfinite(result[i])) {
                    LogManager.logW(TAG, "Softmaxå½’ä¸€åŒ–ç»“æœå¼‚å¸¸ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ");
                    float uniformValue = 1.0f / logits.length;
                    for (int j = 0; j < result.length; j++) {
                        result[j] = uniformValue;
                    }
                    return result;
                }
            }
            
            return result;
            
        } catch (Exception e) {
            LogManager.logE(TAG, "Softmaxè®¡ç®—å¼‚å¸¸: " + e.getMessage());
            // è¿”å›å‡åŒ€åˆ†å¸ƒä½œä¸ºå¤‡ç”¨
            float uniformValue = 1.0f / logits.length;
            for (int i = 0; i < result.length; i++) {
                result[i] = uniformValue;
            }
            return result;
        }
    }
    
    /**
     * å°†æ–‡æ¡£åˆ—è¡¨è½¬æ¢ä¸ºRerankResultåˆ—è¡¨ï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
     */
    private List<RerankResult> convertToRerankResults(List<String> documents) {
        List<RerankResult> results = new ArrayList<>();
        for (int i = 0; i < documents.size(); i++) {
            // Use decreasing scores to maintain original order
            float score = 1.0f - (i * 0.01f);
            results.add(new RerankResult(documents.get(i), score, i));
        }
        return results;
    }
    
    /**
     * æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åˆå§‹åŒ–
     */
    public boolean isInitialized() {
        return isInitialized.get();
    }
    
    /**
     * è·å–æ¨¡å‹è·¯å¾„
     */
    public String getModelPath() {
        return modelPath;
    }
    
    /**
     * æ£€æŸ¥ONNXä¼šè¯çŠ¶æ€å¹¶å°è¯•æ¢å¤
     * @return ä¼šè¯æ˜¯å¦å¯ç”¨
     */
    private boolean checkAndRecoverSession() {
        // Record current thread information
        //LogManager.logD(TAG, "Checking session status [Thread ID: " + Thread.currentThread().getId() + "]");
        
        synchronized (sessionLock) {
            // Record last check time
            lastSessionCheckTime = System.currentTimeMillis();
            
            // Check if session is available
            if (session != null && sessionState == SESSION_STATE_READY) {
                //LogManager.logD(TAG, "Session status is normal, ready to use");
                return true;
            }
            
            // If session is loading, wait for a while
            if (sessionState == SESSION_STATE_LOADING) {
                LogManager.logD(TAG, "Session is loading, waiting...");
                try {
                    // Wait for up to 3 seconds
                    for (int i = 0; i < 30; i++) {
                        // Check every 100 milliseconds
                        Thread.sleep(100);
                        if (session != null && sessionState == SESSION_STATE_READY) {
                            LogManager.logD(TAG, "Session loading completed, ready to use");
                            return true;
                        }
                    }
                } catch (InterruptedException e) {
                    LogManager.logE(TAG, "Waiting for session loading was interrupted: " + e.getMessage());
                    Thread.currentThread().interrupt();
                }
            }
            
            // If session is unavailable or in error state, attempt recovery
            if (session == null || sessionState == SESSION_STATE_ERROR) {
                // Check retry count
                if (sessionRetryCount >= MAX_SESSION_RETRY) {
                    LogManager.logE(TAG, "Session recovery failed, maximum retry count reached: " + sessionRetryCount);
                    return false;
                }
                
                LogManager.logD(TAG, "Attempting to recover session, current retry count: " + sessionRetryCount);
                
                // Update session state
                int oldState = sessionState;
                sessionState = SESSION_STATE_LOADING;
                LogManager.logD(TAG, "Session state changed: " + oldState + " -> " + sessionState + " (starting recovery)");
                
                // Increment retry count
                sessionRetryCount++;
                
                try {
                    // First close the previous session
                    if (session != null) {
                        try {
                            session.close();
                            LogManager.logD(TAG, "Closed old ONNX session");
                        } catch (Exception e) {
                            LogManager.logE(TAG, "Failed to close old ONNX session: " + e.getMessage(), e);
                        } finally {
                            session = null;
                        }
                    }
                    
                    // Reinitialize the model
                    try {
                        LogManager.logD(TAG, "Reinitializing rerank model: " + modelPath);
                        
                        // Reset state
                        isInitialized.set(false);
                        isLoading.set(false);
                        
                        // Call initialization method (but avoid infinite recursion)
                        boolean success = initializeInternal();
                        
                        if (success && session != null) {
                            LogManager.logD(TAG, "Rerank model session recovery successful");
                            sessionState = SESSION_STATE_READY;
                            return true;
                        } else {
                            LogManager.logE(TAG, "Rerank model session recovery failed, session is null");
                            sessionState = SESSION_STATE_ERROR;
                            return false;
                        }
                    } catch (Exception e) {
                        LogManager.logE(TAG, "Failed to reinitialize rerank model: " + e.getMessage(), e);
                        sessionState = SESSION_STATE_ERROR;
                        return false;
                    }
                } finally {
                    // If session is still null, ensure state is ERROR
                    if (session == null && sessionState != SESSION_STATE_ERROR) {
                        LogManager.logE(TAG, "Session is null but state is not ERROR, correcting state");
                        sessionState = SESSION_STATE_ERROR;
                    }
                    
                    // Record session recovery result
                    boolean success = session != null && sessionState == SESSION_STATE_READY;
                    LogManager.logD(TAG, "Session recovery " + (success ? "successful" : "failed") + 
                           ", final state: " + sessionState + 
                           ", retry count: " + sessionRetryCount + "/" + MAX_SESSION_RETRY);
                }
            }
            
            // Session is still unavailable
            LogManager.logE(TAG, "Session check completed, session still unavailable, state: " + sessionState);
            return false;
        }
    }
    
    /**
     * å†…éƒ¨åˆå§‹åŒ–æ–¹æ³•ï¼Œé¿å…é€’å½’è°ƒç”¨
     */
    private boolean initializeInternal() {
        // Implement simplified initialization logic here, avoiding calls to checkAndRecoverSession
        try {
            // Check if model file exists
            File modelFile = new File(modelPath);
            if (!modelFile.exists()) {
                LogManager.logE(TAG, "Rerank model file does not exist: " + modelPath);
                return false;
            }
            
            // Create ONNX environment
            if (environment == null) {
                environment = OrtEnvironment.getEnvironment();
            }
            
            // Create session options
            OrtSession.SessionOptions sessionOptions = new OrtSession.SessionOptions();
            int threadCount = ConfigManager.getThreads(context);
            sessionOptions.setIntraOpNumThreads(threadCount);
            sessionOptions.setInterOpNumThreads(threadCount);
            sessionOptions.setMemoryPatternOptimization(true);
            sessionOptions.setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL);
            
            // Load model
            session = environment.createSession(modelPath, sessionOptions);
            
            if (session != null) {
                isInitialized.set(true);
                return true;
            }
            
            return false;
        } catch (Exception e) {
            LogManager.logE(TAG, "Internal initialization failed: " + e.getMessage(), e);
            return false;
        }
    }
    
    /**
     * è·å–å½“å‰TokenizerManagerå®ä¾‹å¹¶éªŒè¯çŠ¶æ€
     * @return æœ‰æ•ˆçš„TokenizerManagerå®ä¾‹ï¼Œå¦‚æœæ— æ•ˆåˆ™è¿”å›null
     */
    private TokenizerManager getCurrentTokenizerManager() {
        try {
            TokenizerManager manager = TokenizerManager.getInstance(context);
            if (manager != null && manager.isInitialized()) {
                LogManager.logD(TAG, "TokenizerManagerçŠ¶æ€éªŒè¯é€šè¿‡: å®ä¾‹æœ‰æ•ˆä¸”å·²åˆå§‹åŒ–");
                return manager;
            } else {
                LogManager.logW(TAG, "TokenizerManagerå®ä¾‹æ— æ•ˆæˆ–æœªåˆå§‹åŒ–");
                if (manager == null) {
                    LogManager.logW(TAG, "  - TokenizerManagerå®ä¾‹ä¸ºnull");
                } else {
                    LogManager.logW(TAG, "  - TokenizerManagerå®ä¾‹å­˜åœ¨ä½†æœªåˆå§‹åŒ–");
                }
                return null;
            }
        } catch (Exception e) {
            LogManager.logE(TAG, "è·å–TokenizerManagerå®ä¾‹æ—¶å‘ç”Ÿå¼‚å¸¸: " + e.getMessage(), e);
            return null;
        }
    }
    
    /**
     * æ£€æŸ¥TokenizerManagerçŠ¶æ€çš„è¯¦ç»†ä¿¡æ¯
     * @return çŠ¶æ€æ£€æŸ¥æŠ¥å‘Š
     */
    public String checkTokenizerManagerStatus() {
        StringBuilder report = new StringBuilder();
        report.append("=== TokenizerManagerçŠ¶æ€æ£€æŸ¥æŠ¥å‘Š ===\n");
        
        try {
            TokenizerManager manager = TokenizerManager.getInstance(context);
            if (manager == null) {
                report.append("âŒ TokenizerManagerå®ä¾‹: null\n");
                return report.toString();
            }
            
            report.append("âœ… TokenizerManagerå®ä¾‹: å­˜åœ¨\n");
            report.append("ğŸ“‹ åˆå§‹åŒ–çŠ¶æ€: ").append(manager.isInitialized() ? "å·²åˆå§‹åŒ–" : "æœªåˆå§‹åŒ–").append("\n");
            
            if (manager.isInitialized()) {
                // å¯ä»¥æ·»åŠ æ›´å¤šçŠ¶æ€æ£€æŸ¥
                report.append("ğŸ”§ åˆ†è¯å™¨å¯ç”¨æ€§: å¯ç”¨\n");
            } else {
                report.append("âš ï¸ åˆ†è¯å™¨å¯ç”¨æ€§: ä¸å¯ç”¨\n");
            }
            
        } catch (Exception e) {
            report.append("âŒ çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: ").append(e.getMessage()).append("\n");
        }
        
        return report.toString();
    }
    
    /**
     * éªŒè¯TokenizerManagerçŠ¶æ€å¹¶å°è¯•é‡æ–°åˆå§‹åŒ–
     * @return æ˜¯å¦æˆåŠŸè·å–æœ‰æ•ˆçš„TokenizerManager
     */
    private boolean validateAndReinitializeTokenizer() {
        TokenizerManager manager = getCurrentTokenizerManager();
        if (manager != null) {
            return true;
        }
        
        LogManager.logW(TAG, "TokenizerManagerçŠ¶æ€æ— æ•ˆï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–...");
        try {
            // å°è¯•é‡æ–°è·å–å¹¶åˆå§‹åŒ–TokenizerManager
            manager = TokenizerManager.getInstance(context);
            if (manager != null) {
                // è·å–æ¨¡å‹ç›®å½•è¿›è¡Œé‡æ–°åˆå§‹åŒ–
                File modelFile = new File(modelPath);
                File modelDir = modelFile.getParentFile();
                if (modelDir != null && modelDir.exists()) {
                    boolean success = manager.initialize(modelDir);
                    if (success) {
                        LogManager.logI(TAG, "TokenizerManageré‡æ–°åˆå§‹åŒ–æˆåŠŸ");
                        return true;
                    }
                }
            }
        } catch (Exception e) {
            LogManager.logE(TAG, "TokenizerManageré‡æ–°åˆå§‹åŒ–å¤±è´¥: " + e.getMessage(), e);
        }
        
        return false;
    }
    
    /**
     * æ¸…ç†èµ„æº
     */
    public void cleanup() {
        synchronized (sessionLock) {
            try {
                if (session != null) {
                    session.close();
                    session = null;
                }
                if (environment != null) {
                    environment.close();
                    environment = null;
                }
                isInitialized.set(false);
                sessionState = SESSION_STATE_NONE;
                sessionRetryCount = 0;
                lastSessionCheckTime = 0;
                LogManager.logI(TAG, "Rerank model resources have been cleaned up");
            } catch (Exception e) {
                LogManager.logE(TAG, "Error occurred while cleaning up rerank model resources: " + e.getMessage(), e);
            }
        }
    }
    
    @Override
    protected void finalize() throws Throwable {
        cleanup();
        super.finalize();
    }
}